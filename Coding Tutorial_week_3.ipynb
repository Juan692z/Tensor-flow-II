{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence modelling \n",
    "\n",
    "## Coding tutorials\n",
    " #### [1.  The IMDb dataset](#coding_tutorial_1)\n",
    " #### [2. Padding and masking sequence data](#coding_tutorial_2)\n",
    " #### [3. The Embedding layer](#coding_tutorial_3)\n",
    " #### [4. The Embedding Projector](#coding_tutorial_4)\n",
    " #### [5. Recurrent neural network layers](#coding_tutorial_5)\n",
    " #### [6. Stacked RNNs and the Bidirectional wrapper](#coding_tutorial_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## The IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import imdb\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download and assign the data set using load_data()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)=imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the type of the data\n",
    "\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the data\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element input\n",
    "# Notice encoding\n",
    "x_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element output\n",
    "y_train[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset with different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core.keras.datasets.imdb' has no attribute 'npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-241b27071fcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the dataset with defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# ~/.keras/dataset/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core.keras.datasets.imdb' has no attribute 'npz'"
     ]
    }
   ],
   "source": [
    "# Load the dataset with defaults\n",
    "\n",
    "imdb.load_data(path=imdb.npz\n",
    "              index_from=3)\n",
    "# ~/.keras/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the vocabulary to the top 500 words using num_words\n",
    "imdb.load_data(num_worls=500)\n",
    "#Indices de palabras menores a 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the top 10 most frequent words using skip_top\n",
    "\n",
    "imdb.load_data(skip_top=10, num_worls=1000, ovv_chart=2)\n",
    "#SKIPTOP Elimina las 10 palabras m√°s repetidas\n",
    "#OVV_CHART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the sequence lengths to 500 using maxlen\n",
    "imdb.load_data(maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use '1' as the character that indicates the start of a sequence\n",
    "imdb.load_data(start_chart=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the imdb word index using get_word_index()\n",
    "\n",
    "imdb_word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the word index as a dictionary,\n",
    "# accounting for index_from.\n",
    "index_from=3\n",
    "imdb_word_index = {key: value + index_from for key, value in imdb_word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52256"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a specific word's index\n",
    "\n",
    "imdb_word_index['simpsonian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View an input sentence\n",
    "\n",
    "imdb_word_index['the']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inv_imdb_word_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d0b39813fa1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minv_get_word_index\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimdb_word_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0minv_imdb_word_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mindex_from\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-d0b39813fa1d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minv_get_word_index\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimdb_word_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0minv_imdb_word_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mindex_from\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inv_imdb_word_index' is not defined"
     ]
    }
   ],
   "source": [
    "inv_get_word_index= {value: key for key, value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_train[0] if index> index_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sentiment value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Padding and Masking Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the imdb data set\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb\n",
    "(x_train, y_train), (x_test, y_test) =  imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the input data shape\n",
    "x_train.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the inputs to the maximum length using maxlen\n",
    "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=300, padding='post', truncating='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the output data shape\n",
    "padded_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masking expects to see (batch, sequence, features)\n",
    "# Create a dummy feature dimension using expand_dims\n",
    "\n",
    "padded_x_train= np.expand_dims(x_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8c0848a967b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a Masking layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf_x_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmasking_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMasking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Create a Masking layer \n",
    "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
    "masking_layer = tf.keras.layers.Masking(mask_value=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masking_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3b3b141aef50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Pass tf_x_train to it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmasked_x_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasking_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_x_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'masking_layer' is not defined"
     ]
    }
   ],
   "source": [
    "# Pass tf_x_train to it\n",
    "\n",
    "masked_x_train = masking_layer(tf_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask_x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ee8ed0eeaab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#tf_x_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmask_x_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mask_x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Look at the dataset\n",
    "\n",
    "#tf_x_train\n",
    "mask_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the ._keras_mask for the dataset\n",
    "\n",
    "mask_x_train._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer using layers.Embedding\n",
    "# Specify input_dim, output_dim, input_length\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=17, shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
       "array([[[[ 0.0069194 , -0.00051308, -0.02257497,  0.03406408,\n",
       "           0.04044045, -0.03777949,  0.04580034, -0.02451481,\n",
       "           0.03691988,  0.01943647,  0.001205  ,  0.01804275,\n",
       "           0.02926356, -0.03445012, -0.00934314, -0.02872245]],\n",
       "\n",
       "        [[ 0.04897299, -0.01890786,  0.00371199,  0.02906594,\n",
       "          -0.00824763, -0.04620586, -0.04369418, -0.00364195,\n",
       "          -0.03458989, -0.00050274,  0.00542338,  0.00809407,\n",
       "           0.03215338, -0.01320235, -0.04520104, -0.02037505]],\n",
       "\n",
       "        [[-0.00744956,  0.04699873, -0.01853855,  0.0075155 ,\n",
       "           0.02800563, -0.03232055, -0.03598322, -0.04918769,\n",
       "          -0.00998803, -0.01107083, -0.0108227 ,  0.03720902,\n",
       "           0.00965389,  0.04553646,  0.01693473, -0.01860042]],\n",
       "\n",
       "        [[ 0.00470209, -0.0357327 ,  0.03182837,  0.01844818,\n",
       "          -0.00860488, -0.03236121,  0.03826029,  0.02279893,\n",
       "           0.01501941, -0.03677896,  0.01798793,  0.01079249,\n",
       "          -0.03934603,  0.04793593, -0.01802794,  0.02770462]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an Embedding layer output for a fixed input\n",
    "# Expects an input of shape (batch, sequence, feature)\n",
    "\n",
    "sequence_of_indices = tf.constant([[[0],[1],[5],[500]]])\n",
    "\n",
    "\n",
    "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
    "sequence_of_embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.0069194 , -0.00051308, -0.02257497, ..., -0.03445012,\n",
       "         -0.00934314, -0.02872245],\n",
       "        [ 0.04897299, -0.01890786,  0.00371199, ..., -0.01320235,\n",
       "         -0.04520104, -0.02037505],\n",
       "        [-0.01592297,  0.00154154,  0.04568121, ..., -0.03053335,\n",
       "         -0.04904708,  0.03295827],\n",
       "        ...,\n",
       "        [ 0.03349483,  0.03034044, -0.02474043, ...,  0.02177416,\n",
       "         -0.03325158,  0.02347883],\n",
       "        [ 0.01429157,  0.02229356,  0.03058967, ..., -0.04349237,\n",
       "          0.03069759,  0.03156577],\n",
       "        [ 0.00470209, -0.0357327 ,  0.03182837, ...,  0.04793593,\n",
       "         -0.01802794,  0.02770462]], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Embedding layer weights using get_weights()\n",
    "embedding_layer.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01310291,  0.00847652, -0.02740347,  0.02939374, -0.02005616,\n",
       "        0.0155687 , -0.04428743,  0.03473911,  0.02963928, -0.00611085,\n",
       "       -0.04729985,  0.02734074,  0.04625619, -0.04110263, -0.02378829,\n",
       "       -0.03825284], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the 14th index\n",
    "\n",
    "embedding_layer.get_weights()[0][14,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create a layer that uses the mask_zero kwarg\n",
    "\n",
    "masking_embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16, mask_zero = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=41, shape=(1, 4, 1), dtype=bool, numpy=\n",
       "array([[[False],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply this layer to the sequence and see the _keras_mask property\n",
    "\n",
    "masked_sequence_of_embeddings = masking_embedding_layer(sequence_of_indices)\n",
    "masked_sequence_of_embeddings._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Embedding Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test)= get_and_pad_imdb_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Get the word index\n",
    "\n",
    "imdb_word_index =  get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the keys and values of the word index\n",
    "inv_imdb_word_index = {value : key for key, value in imdb_word_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'and',\n",
       " 'have',\n",
       " 'everything',\n",
       " 'that',\n",
       " \"he's\",\n",
       " 'made',\n",
       " 'on',\n",
       " 'dvd',\n",
       " 'except',\n",
       " 'for',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'the',\n",
       " '2',\n",
       " 'hour',\n",
       " 'twin',\n",
       " 'peaks',\n",
       " 'movie',\n",
       " 'so',\n",
       " 'when',\n",
       " 'i',\n",
       " 'found',\n",
       " 'out',\n",
       " 'about',\n",
       " 'this',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'grabbed',\n",
       " 'it',\n",
       " 'and',\n",
       " 'and',\n",
       " 'what',\n",
       " 'is',\n",
       " 'this',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'drawn',\n",
       " 'black',\n",
       " 'and',\n",
       " 'white',\n",
       " 'cartoons',\n",
       " 'that',\n",
       " 'are',\n",
       " 'loud',\n",
       " 'and',\n",
       " 'foul',\n",
       " 'mouthed',\n",
       " 'and',\n",
       " 'unfunny',\n",
       " 'maybe',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " \"what's\",\n",
       " 'good',\n",
       " 'but',\n",
       " 'maybe',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'crap',\n",
       " 'that',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'public',\n",
       " 'under',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'few',\n",
       " 'bucks',\n",
       " 'too',\n",
       " 'let',\n",
       " 'me',\n",
       " 'make',\n",
       " 'it',\n",
       " 'clear',\n",
       " 'that',\n",
       " 'i',\n",
       " \"didn't\",\n",
       " 'care',\n",
       " 'about',\n",
       " 'the',\n",
       " 'foul',\n",
       " 'language',\n",
       " 'part',\n",
       " 'but',\n",
       " 'had',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'because',\n",
       " 'my',\n",
       " 'neighbors',\n",
       " 'might',\n",
       " 'have',\n",
       " 'all',\n",
       " 'in',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'highly',\n",
       " 'disappointing',\n",
       " 'release',\n",
       " 'and',\n",
       " 'may',\n",
       " 'well',\n",
       " 'have',\n",
       " 'just',\n",
       " 'been',\n",
       " 'left',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " 'set',\n",
       " 'as',\n",
       " 'a',\n",
       " 'curiosity',\n",
       " 'i',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'you',\n",
       " \"don't\",\n",
       " 'spend',\n",
       " 'your',\n",
       " 'money',\n",
       " 'on',\n",
       " 'this',\n",
       " '2',\n",
       " 'out',\n",
       " 'of',\n",
       " '10']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first dataset example sentence\n",
    "[inv_imdb_word_index[index] for index in x_train[100] if index > 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an Embedding layer into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum token value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an embedding dimension\n",
    "embedding_dim=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using Sequential:\n",
    "#     1. Embedding layer\n",
    "#     2. GlobalAveragePooling1D\n",
    "#     3. Dense\n",
    "\n",
    "model =tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(unit=1, acrivation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API refresher: use the Model to build the same model\n",
    "review_sequence = tf.keras.Input((None, ))\n",
    "embedding_sequence = tf.keras.layers.Embedding(input_dim = max_index_value+1, output_dim=embedding_dim)(review_sequence)\n",
    "average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
    "\n",
    "model = tf.keras.Model(inputs = review_sequence, outputs=positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile, train, and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a binary cross-entropy loss\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 38s 2ms/sample - loss: 0.6899 - accuracy: 0.5465 - val_loss: 0.0175 - val_accuracy: 0.5781\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 36s 1ms/sample - loss: 0.6678 - accuracy: 0.6834 - val_loss: 0.0166 - val_accuracy: 0.7203\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 37s 1ms/sample - loss: 0.6192 - accuracy: 0.7598 - val_loss: 0.0151 - val_accuracy: 0.7453\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 35s 1ms/sample - loss: 0.5641 - accuracy: 0.7987 - val_loss: 0.0138 - val_accuracy: 0.7953\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 36s 1ms/sample - loss: 0.5141 - accuracy: 0.8215 - val_loss: 0.0127 - val_accuracy: 0.8016\n"
     ]
    }
   ],
   "source": [
    "# Train the model using .fit(), savng its history\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), validation_steps=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The TensorFlow embedding projector\n",
    "\n",
    "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embedding layer's weights from the trained model\n",
    "weights= model.layers[1].get_weights()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/vecs.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-07d4ece34681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mout_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vecs.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mout_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meta.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/vecs.tsv'"
     ]
    }
   ],
   "source": [
    "# Save the word Embeddings to tsv files\n",
    "# Two files: \n",
    "#     one contains the embedding labels (meta.tsv),\n",
    "#     one contains the embeddings (vecs.tsv)\n",
    "\n",
    "import io\n",
    "from os import path\n",
    "\n",
    "out_v = io.open(path.join('data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
    "out_m = io.open(path.join('data', 'meta.tsv'), 'w', encoding='utf-8')\n",
    "\n",
    "k = 0\n",
    "\n",
    "for word, token in word_index.items():\n",
    "    if k != 0:\n",
    "        out_m.write('\\n')\n",
    "        out_v.write('\\n')\n",
    "    \n",
    "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
    "    out_m.write(word)\n",
    "    k += 1\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()\n",
    "# beware large collections of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Recurrent neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and pass an input to a SimpleRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleRNN layer and test it\n",
    "\n",
    "simplernn_layer = tf.keras.layers.SimpleRNN(units=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=121, shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ 0.9999915 , -1.        ,  1.        , -1.        ,  1.        ,\n",
       "        -1.        ,  1.        , -1.        ,  1.        , -1.        ,\n",
       "        -1.        ,  1.        , -1.        ,  0.99999964,  1.        ,\n",
       "         1.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that only the final cell output is returned\n",
    "sequence = tf.constant([[[1., 1.], [2., 2.], [56., -100.]]])\n",
    "layer_output = simplernn_layer(sequence)\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "imdb_word_index = get_imdb_word_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build the model:\n",
    "# 1. Embedding.\n",
    "# 2. LSTM.\n",
    "# 3. Dense.\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim = max_index_value+1,output_dim = embedding_dim, mask_zero = True),\n",
    "    tf.keras.layers.LSTM(units=16),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary cross-entropy loss\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 524s 21ms/sample - loss: 0.4013 - accuracy: 0.8176\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 495s 20ms/sample - loss: 0.2261 - accuracy: 0.9140\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 467s 19ms/sample - loss: 0.1763 - accuracy: 0.9362\n"
     ]
    }
   ],
   "source": [
    "# Fit the model and save its training history\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3b8680024394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0macc\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mval_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mloss\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first test data example sentence\n",
    "# (invert the word index)\n",
    "inv_imdb_index= {value: key for key value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_test[0] if index>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model prediction using model.predict()\n",
    "\n",
    "model.predict(x_test[None, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the corresponding label\n",
    "y_test[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_6\"></a>\n",
    "## Stacked RNNs and the Bidirectional wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(num_words = 5000, maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build stacked and bidirectional recurrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value and specify an embedding dimension\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(units=12, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(units=12, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8), merge_mode='sum', backward_layer= tf.keras.layers.GRU(units=8, go_backwards= True)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
    "model =  tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8, return_sequences= True), merge_mode='concat'),\n",
    "    tf.keras.layers.GRU(units=8, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "\r",
      "   32/25000 [..............................] - ETA: 5s"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0c715085624e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model, saving its history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# Train the model, saving its history\n",
    "history = model.fit(x_train, y_train, epochs=3, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
